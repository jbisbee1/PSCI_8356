
\documentclass[11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[abbr]{harvard}
\usepackage{amssymb}
\usepackage{setspace,graphics,epsfig,amsmath,rotating,amsfonts,mathpazo}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=BibTeX}
%TCIDATA{Created=Thursday, September 11, 2008 15:11:56}
%TCIDATA{LastRevised=Sunday, September 29, 2013 12:51:12}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Articles\SW\article.egan">}

\topmargin=0 in \headheight=0in \headsep=0in \topskip=0in \textheight=9in \oddsidemargin=0in \evensidemargin=0in \textwidth=6.5in
\input{tcilatex}
\setcounter{section}{1}

\begin{document}


New York University

Wilf Family Department of Politics

Fall 2013

\begin{center}
{\large \textbf{Quantitative Research in Political\ Science I}}

Professor Patrick Egan

\bigskip

\textbf{Some Helpful Results Regarding the Math of\ Expectations }

\textbf{(For the Case of a Discrete Random\ Variable)}
\end{center}

\bigskip In all cases, $Y$ is assumed to be a discrete random variable with
a probability function $p(y)$ that accurately characterizes a population
frequency distribution. \ With the exception of the final result, proofs are
omitted. \ They may be found in WMS (pp. 93, 95).\bigskip 

\subsection{Definitions}

\bigskip

\begin{eqnarray*}
E(Y) &\equiv &\sum_{y}yp(y)=\mu . \\
&& \\
VAR(Y) &\equiv &E[(Y-\mu )^{2}]=\sigma ^{2}.
\end{eqnarray*}%
\bigskip

\subsection{Functions of a random variable\protect\bigskip}

\begin{itemize}
\item Where $g(Y)$ is a real-valued function of $Y$,
\end{itemize}

\begin{equation*}
E[g(Y)]=\sum_{y}g(y)p(y).
\end{equation*}

\begin{itemize}
\item Where $g_{1},g_{2}...g_{k}$ are $k$ real-valued functions of $Y$, we
can \textquotedblleft distribute expectations\textquotedblright :
\end{itemize}

\begin{equation*}
E[g_{1}(Y)+g_{2}(Y)+...+g_{k}(Y)]=E[g_{1}(Y)]+E[g_{2}(Y)]+...+E[g_{k}(Y)].
\end{equation*}%
\bigskip

\subsection{Constants\protect\bigskip}

\begin{itemize}
\item Where $c$ is a constant,%
\begin{equation*}
E(c)=c,
\end{equation*}

and%
\begin{equation*}
E[cg(Y)]=cE[g(Y)].
\end{equation*}

\item Population parameters, such as $\mu $ and $\sigma ^{2},$ are
constants.\bigskip 
\end{itemize}

\subsection{The variance of a random variable}

\medskip \bigskip

\begin{equation*}
\sigma ^{2}=E(Y^{2})-\mu ^{2}.
\end{equation*}

Proof:

\begin{eqnarray*}
\sigma ^{2} &=&VAR(Y)\equiv E[(Y-\mu )^{2}] \\
&=&E(Y^{2}+\mu ^{2}-2Y\mu )\text{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\ \ [Expanding the quadratic]} \\
&=&E(Y^{2})+E(\mu ^{2})-E(2Y\mu )\text{ \ \ \ \ \ \ \ \ \ \ \ [Distributing
expectations]} \\
&=&E(Y^{2})+\mu ^{2}-2\mu E(Y)\text{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [}2%
\text{, and }\mu \text{ (a population parameter) are constants]} \\
&=&E(Y^{2})+\mu ^{2}-2\mu \mu \text{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\ \ \ [}E(Y)=\mu \text{]} \\
&=&E(Y^{2})-\mu ^{2}\text{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\ \ \ \ \ \ \ \ \ \ }\blacksquare . \\
&&
\end{eqnarray*}

\end{document}
