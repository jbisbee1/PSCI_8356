
\documentclass[11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[abbr]{harvard}
\usepackage{amssymb}
\usepackage{setspace,graphics,epsfig,amsmath,rotating,amsfonts,mathpazo}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=BibTeX}
%TCIDATA{Created=Thursday, September 11, 2008 15:11:56}
%TCIDATA{LastRevised=Sunday, December 01, 2013 17:29:58}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Articles\SW\article.egan">}

\topmargin=0 in \headheight=0in \headsep=0in \topskip=0in \textheight=9in \oddsidemargin=0in \evensidemargin=0in \textwidth=6.5in
\input{tcilatex}
\begin{document}


New York University

Wilf Family Department of Politics

\begin{center}
{\large \textbf{Quantitative Research in Political\ Science I}}

Professor Patrick Egan

\bigskip

\textbf{Omitted Variables Bias (OVB)}
\end{center}

\bigskip {\small BIVARIATE\ REGRESSION}\bigskip

\begin{tabular}{ll}
\hline
{\small linear model} & ${\small y=\beta }_{0}{\small +\beta }_{1}{\small x+u%
}$ \\ \hline
{\small least-squares estimator} & $\widehat{\beta }_{1}{\small \equiv }%
\frac{cov\left( x,y\right) }{var\left( x\right) }$ \\ \hline
{\small expected value of estimator} & ${\small E}\left( \widehat{\beta }%
_{1}\right) {\small =\beta }_{1}{\small +}\frac{1}{SST_{x}}{\small E}\left[
\sum \left( x_{i}-\overline{x}\right) u_{i}\right] $ \\ \hline
{\small conditional independence assumption} & $E(u|x)=0${\small \ \ } \\ 
\hline
but what if true DGP\QQfnmark{%
DGP = \textquotedblleft data generating process\textquotedblright : the (at
least partially unobserved) social process that generates $y.$} is: & $%
{\small y=\beta }_{0}{\small +\beta }_{1}{\small x+\mathbf{z}}^{\prime }%
{\small \mathbf{\gamma }+v}$ \\ \hline
then the {\small OVB formula is:} & $\widehat{\beta }_{1}{\small =\beta }_{1}%
{\small +\mathbf{\gamma }}^{\prime }\mathbf{\delta }_{zx}$ \\ \hline
\end{tabular}%
\QQfntext{0}{
DGP = \textquotedblleft data generating process\textquotedblright : the (at
least partially unobserved) social process that generates $y.$}

\bigskip The scalar ${\small \mathbf{\gamma }}^{\prime }\mathbf{\delta }%
_{zx} $ is the product of:

\begin{itemize}
\item $\mathbf{\delta }_{zx},$ the vector of coefficients from the separate
regressions of each of the variables in ${\small \mathbf{z}}$ on $x,$ and

\item $\mathbf{\gamma }$, a vector whose elements are the coefficients from
the regressions of $y$ on each of the elements of $\mathbf{z}$.
\end{itemize}

\newpage 

{\small MULTIPLE\ REGRESSION}\bigskip 

\begin{tabular}{ll}
\hline
{\small linear model} & $\mathbf{y=X\beta +u}$, where $\mathbf{X}$ is an $%
N\times K$ matrix \\ \hline
{\small least-squares estimator} & $\widehat{\mathbf{\beta }}{\small \equiv }%
\left( \mathbf{X}^{\prime }\mathbf{X}\right) ^{-1}\mathbf{X}^{\prime }%
\mathbf{y}$ \\ \hline
{\small expected value of estimator} & ${\small E}\left( \widehat{\mathbf{%
\beta }}\right) {\small =\mathbf{\beta }+E}\left[ \left( \mathbf{X}^{\prime }%
\mathbf{X}\right) ^{-1}\mathbf{X}^{\prime }\mathbf{u}\right] $ \\ \hline
{\small conditional independence assumption} & $E\left( \mathbf{u}|\mathbf{X}%
\right) =0${\small \ } \\ \hline
but what if true DGP is: & $\mathbf{y=X\beta +Z\gamma +v}$, where $\mathbf{Z}
$ is an $N\times J$ matrix \\ \hline
then the {\small OVB formula is:} & $\widehat{\mathbf{\beta }}=\mathbf{%
\mathbf{\beta +}}\left( \mathbf{X}^{\prime }\mathbf{X}\right) ^{-1}\left( 
\mathbf{X}^{\prime }\mathbf{Z}\right) \mathbf{\gamma }$ \\ \hline
\end{tabular}

\bigskip Here, $\left( \mathbf{X}^{\prime }\mathbf{X}\right) ^{-1}\left( 
\mathbf{X}^{\prime }\mathbf{Z}\right) \mathbf{\gamma }$ is a $K\times 1$
\textquotedblleft correction vector,\textquotedblright\ the product of:

\begin{itemize}
\item $\mathbf{\gamma }$, a $J\times 1$ vector whose elements are the
coefficients from the regressions of $y$ on each of the $J$ elements of $%
\mathbf{z}$, and

\item $\left( \mathbf{X}^{\prime }\mathbf{X}\right) ^{-1}\left( \mathbf{X}%
^{\prime }\mathbf{Z}\right) ,$ the $K\times J$ matrix whose columns are the
coefficients from the $J$ separate regressions of each of the variables in $%
\mathbf{Z}$ on the $K$ variables in $\mathbf{X}$. \ We might write this as%
\begin{equation*}
\left( \mathbf{X}^{\prime }\mathbf{X}\right) ^{-1}\left( \mathbf{X}^{\prime }%
\mathbf{Z}\right) =%
\begin{bmatrix}
\delta _{11} & \delta _{12} & ... & \delta _{1J} \\ 
\delta _{21} & \ddots  &  &  \\ 
\vdots  &  &  &  \\ 
\delta _{K1} &  &  & \delta _{KJ}%
\end{bmatrix}%
,
\end{equation*}

\item Thus we can write%
\begin{eqnarray*}
\widehat{\mathbf{\beta }} &=&\mathbf{\mathbf{\beta +}}\left( \mathbf{X}%
^{\prime }\mathbf{X}\right) ^{-1}\left( \mathbf{X}^{\prime }\mathbf{Z}%
\right) \mathbf{\gamma } \\
\begin{bmatrix}
\widehat{\beta }_{1} \\ 
\widehat{\beta }_{2} \\ 
\vdots  \\ 
\widehat{\beta }_{K}%
\end{bmatrix}
&=&%
\begin{bmatrix}
\beta _{1} \\ 
\beta _{2} \\ 
\vdots  \\ 
\beta _{K}%
\end{bmatrix}%
+%
\begin{bmatrix}
\delta _{11} & \delta _{12} & ... & \delta _{1J} \\ 
\delta _{21} & \ddots  &  &  \\ 
\vdots  &  &  &  \\ 
\delta _{K1} &  &  & \delta _{KJ}%
\end{bmatrix}%
\begin{bmatrix}
\gamma _{1} \\ 
\gamma _{2} \\ 
\vdots  \\ 
\gamma _{J}%
\end{bmatrix}%
\end{eqnarray*}

\bigskip So what does this tell us about the OVB formula for some generic
element of $\widehat{\mathbf{\beta }}$, $\widehat{\beta }_{k}$? \ 
\begin{equation*}
\widehat{\beta }_{k}=\beta _{k}+\delta _{k1}\gamma _{1}+\delta _{k2}\gamma
_{2}+...\delta _{kJ}\gamma _{J}
\end{equation*}

\item Thus $\widehat{\beta }_{k}$ is biased by the sum of $J$ products
consisting of:

\begin{itemize}
\item $\delta _{kj}$, the coefficient on $x_{k}$ in the regression of $z_{j}$
on $\mathbf{x,}$ multiplied by

\item $\gamma _{j}$, the coefficient on $z_{j}$ in the regression of $y$ on $%
\mathbf{z}$.
\end{itemize}
\end{itemize}

\end{document}
